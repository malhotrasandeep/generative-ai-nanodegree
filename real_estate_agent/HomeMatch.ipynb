{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a108af04",
   "metadata": {},
   "source": [
    "This is a starter notebook for the project, you'll have to import the libraries you'll need, you can find a list of the ones available in this workspace in the requirements.txt file in this workspace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6554fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas langchain_chroma langchain_openai langchain_core langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9858c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from uuid import uuid4\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "import tiktoken\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796aac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"<API_KEY>\"\n",
    "#os.environ[\"OPENAI_API_BASE\"] = <BASE_API_KEY>\"  #needed for Udacity project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b6286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_listing(n_listing):\n",
    "    #generate the list of home properties\n",
    "    model_name = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "    model = OpenAI(model_name=model_name,\n",
    "                            temperature=0, \n",
    "                            max_tokens=2000)\n",
    "\n",
    "    template_str = \"\"\"\n",
    "    Create a listing of {n_listing} home properties in Texas, US. \n",
    "\n",
    "    Create approximately equal split of the no. of bedrooms with the minimum no. of bedrooms as 1 and max no. of bedrooms as 5\n",
    "\n",
    "    The listing should be in the json format with following fields:\n",
    "\n",
    "    Neighborhood, Price, No. of bedrooms, No. of bathrooms, House size, House Description, Neighbourhood Description.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt_template = PromptTemplate.from_template(template_str)\n",
    "    prompt = prompt_template.format_prompt(n_listing=n_listing)\n",
    "\n",
    "    response = model.invoke(prompt)\n",
    "    \n",
    "    data = json.loads(response)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(\"property_listings.csv\",index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89cc8bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_store():\n",
    "    #Embedding function\n",
    "    embedding_fn = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    \n",
    "    # initialie Chroma DB\n",
    "    vector_store = Chroma(collection_name=\"temp\",\n",
    "                          embedding_function=embedding_fn,\n",
    "                          persist_directory=\"./chroma_db\")\n",
    "    \n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37014e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_data_in_vector_store(vector_store):\n",
    "    #load the documents using langchain CSV loader\n",
    "    docs = CSVLoader(\"property_listings.csv\").load()\n",
    "\n",
    "    #split the documents\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    docs_split = text_splitter.split_documents(docs)\n",
    "\n",
    "    #add documents to chroma db with embedding\n",
    "    uuids = [str(uuid4()) for _ in range(len(docs_split))]\n",
    "    vector_store.add_documents(documents=docs_split, ids=uuids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32fd110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_document(vector_store, query):\n",
    "    #set the db as retriever and make a query on the same for similarity\n",
    "    retriever = vector_store.as_retriever()\n",
    "    docs = retriever.invoke(query)\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f539b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_preferences(interactive=False):\n",
    "    '''\n",
    "    if interactive = True, then it will allow users to enter values\n",
    "    otherwise it will take the hardocded values\n",
    "    '''\n",
    "    questions = [   \n",
    "                \"How big do you want your house to be?\",\n",
    "                \"What are 3 most important things for you in choosing this property?\", \n",
    "                \"Which amenities would you like?\", \n",
    "                \"Which transportation options are important to you?\",\n",
    "                \"How urban do you want your neighborhood to be?\",   \n",
    "            ]\n",
    "    qa_list = []\n",
    "    if interactive == True:\n",
    "        for question in questions:\n",
    "            print(question)\n",
    "            answer = input()\n",
    "            qa_list.append((question, answer))\n",
    "    else:\n",
    "        answers = [\"A comfortable three-bedroom house with a spacious kitchen and a cozy living room.\",\n",
    "             \"A quiet neighborhood, good local schools, and convenient shopping options.\",\n",
    "             \"A backyard for gardening, a two-car garage, and a modern, energy-efficient heating system.\",\n",
    "             \"Easy access to a reliable bus line, proximity to a major highway, and bike-friendly roads.\",\n",
    "             \"A balance between suburban tranquility and access to urban amenities like restaurants and theaters.\"]\n",
    "        for i in range(5):\n",
    "            qa_list.append((questions[i], answers[i]))\n",
    "        \n",
    "    return qa_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ad7753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare user_preference summary based on the questions/answers\n",
    "\n",
    "# used online documentation at https://python.langchain.com/docs/how_to/chatbots_memory/ for this piece of code\n",
    "\n",
    "def create_user_preference_summary(user_preferences):\n",
    "    messages = []\n",
    "\n",
    "    for q,a in user_preferences:\n",
    "        messages.append(AIMessage(content=q)),\n",
    "        messages.append(HumanMessage(content=q))\n",
    "\n",
    "    model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"\"\"You are a helpful assistant. \n",
    "\n",
    "                Below is the conversation between AI and user where AI is \n",
    "                trying to understand the prefrerences of the user for recommending a house. In this conversation, AI\n",
    "                has asked some questions to the human regarding user's preference and the human has provided answers \n",
    "                for the same.\n",
    "\n",
    "                Summarize the preferences of the human while purchasing a property based on this\n",
    "                conversation between AI and user. Ensure that all points are covered in the summary. \n",
    "\n",
    "                Summarize each set of message separately and then use these summaries to generate overall summary.\n",
    "\n",
    "                For example:\n",
    "                AIMessage: How big do you want your house to be?\n",
    "                HumanMessage: A comfortable three-bedroom house with a spacious kitchen and a cozy living room.\n",
    "\n",
    "                The above can be summarized to the user wants a comfortable three-bedroom house with a \n",
    "                spacious kitchen and a cozy living room.\n",
    "\n",
    "                In the response, only provide overall summary and call it \"User Preferences:\"\n",
    "\n",
    "                \"\"\"\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt | model\n",
    "\n",
    "    ai_msg = chain.invoke(\n",
    "        {\n",
    "            \"messages\": messages,\n",
    "        }\n",
    "    )\n",
    "    print(ai_msg.content)\n",
    "    \n",
    "    return ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e42542c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_prompt(user_preference_summary, top_docs, max_token_count):\n",
    "    '''\n",
    "    this function will create the custom prompt for the question\n",
    "    '''\n",
    "    #create the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding('cl100k_base')\n",
    "    \n",
    "    prompt_template = \"\"\"\n",
    "                        Answer the question based on the context below, and if the question\n",
    "                        can't be answered based on the context, say \"I don't know\".\n",
    "                        \n",
    "                        Recommend one home onlt and personalize the response to the user's preference as \n",
    "                        much as possible.\n",
    "                        \n",
    "                        In the response highlight the salient features of the recommended home that are in line \n",
    "                        with user's preference\n",
    "\n",
    "                        Context:\n",
    "\n",
    "                        {}\n",
    "\n",
    "                        ---\n",
    "\n",
    "                        Question: Recommend homes based on the context.\n",
    "                        Answer:\n",
    "\n",
    "                       \"\"\"\n",
    "    #calculate the current token count\n",
    "    current_token_count = len(tokenizer.encode(prompt_template))\n",
    "    \n",
    "    context = []\n",
    "    \n",
    "    current_token_count = current_token_count + len(tokenizer.encode(user_preference_summary))\n",
    "    \n",
    "    context.append(user_preference_summary)\n",
    "    \n",
    "#     iterate through the dataframe and add rows to the context\n",
    "#     till the max_token_lenth is reached\n",
    "    for text in top_docs:\n",
    "        additional_token_count = len(tokenizer.encode(text.page_content))\n",
    "        \n",
    "        current_token_count += additional_token_count\n",
    "        \n",
    "        if current_token_count <= max_token_count:\n",
    "            context.append(text.page_content)\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return prompt_template.format(\"\\n\\n###\\n\\n\".join(context))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c2107be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendation(prompt):\n",
    "    \n",
    "    sys_msg = SystemMessage('You are a home recommender system.')\n",
    "    human_msg = HumanMessage(prompt)\n",
    "\n",
    "    prompt_final = [sys_msg, human_msg]\n",
    "\n",
    "    prompt_final\n",
    "    \n",
    "    model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "    completion = model.invoke(prompt)\n",
    "    \n",
    "    return completion.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7926fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate property listing and store the same in ChromaDB\n",
    "def generate_and_store_listings(n_listing):\n",
    "    generate_listing(n_listing=12)\n",
    "    vector_store = get_vector_store()\n",
    "    store_data_in_vector_store(vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18c2a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate home recommendation\n",
    "def recommend_home(interactive=False):\n",
    "    user_preferences = get_user_preferences(interactive)\n",
    "#     print(user_preferences)\n",
    "    user_pref_summary = create_user_preference_summary(user_preferences)\n",
    "    vector_store = get_vector_store()\n",
    "    docs = get_relevant_document(vector_store, user_pref_summary)\n",
    "    # docs\n",
    "    #create the prompt and generate recommendation\n",
    "    prompt = create_custom_prompt(user_pref_summary, docs, 2500)\n",
    "#     print(prompt)\n",
    "    recommendation = generate_recommendation(prompt)\n",
    "    print(\"-\"*30)\n",
    "    print(recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdf6bd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_181/2297008184.py:5: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  model = OpenAI(model_name=model_name,\n"
     ]
    }
   ],
   "source": [
    "generate_and_store_listings(n_listing=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23905f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Preferences:\n",
      "The user wants a comfortable three-bedroom house with a spacious kitchen and a cozy living room. The user values having a good school district, a safe neighborhood, and access to outdoor activities. Additionally, the user prefers amenities such as a gym, pool, and walking trails. In terms of transportation, the user values having easy access to public transportation. Lastly, the user prefers a suburban neighborhood with a mix of urban amenities.\n",
      "------------------------------\n",
      "Based on your preferences for a comfortable three-bedroom house with a spacious kitchen and cozy living room, I would recommend the home in Austin. This home fits your criteria with three bedrooms, two bathrooms, and a spacious 1,500 sqft size. It has a beautiful single-family design with modern finishes and a spacious backyard, perfect for outdoor activities. The neighborhood in Austin is vibrant with great schools and outdoor amenities, fitting your preference for a good school district, safe neighborhood, and access to outdoor activities. Additionally, the suburban feel of Austin with urban amenities aligns with your preference. The price of $500,000 is within your budget range, making it a great choice for you.\n"
     ]
    }
   ],
   "source": [
    "recommend_home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47228f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
